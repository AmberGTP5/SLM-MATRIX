# SLM-MATRIX: A Multi-agent Trajectory Reasoning and Verification Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)


This project introduces SLM-MATRIX, a multi-agent framework designed to improve the accuracy and robustness of language models for data extraction tasks in materials science. It achieves this by exploring diverse reasoning paths via Monte Carlo Tree Search (MCTS) and leveraging a consistency verification mechanism to validate the results.

## Key Features

* **MCTS-based Reasoning Trajectory Generation**: Employs various heuristic actions (e.g., problem decomposition, re-evaluation) to guide language models in generating diverse reasoning paths.
* **Mixture-of-Agents (MoA) Collaboration**: Utilizes models with different capabilities (Proposers, Aggregator) to enhance the quality of the final output.
* **Consistency Verification**: Validates the consistency of results from different reasoning paths through regeneration and semantic judgment to filter out unreliable outputs.

## Installation

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/AmberGTP5/SLM-MATRIX.git
    cd SLM-MATRIX
    ```

2.  **Create and Activate a Virtual Environment (Recommended)**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Set Up API Keys**
    * Create a file named `.env` in the root directory of the project.
    * Add your API credentials to the `.env` file as follows:
        ```
        API_KEY="your_api_key_here"
        API_BASE="[https://api.together.xyz/v1]"

        # If using a second API for the aggregate model in MoA.py
        API_KEY_2="your_second_api_key_here"
        API_BASE_2="your_second_api_base_here"
        ```

## Usage

This repository offers two main modes of operation: direct extraction using the Mixture-of-Agents (MoA) framework, and a more detailed analysis of the reasoning process using Monte Carlo Tree Search (MCTS).

#### Mode 1: Direct Extraction with Mixture-of-Agents (MoA)

For direct, end-to-end data extraction, run the `MoA.py` script. This will launch an interactive session.

1.  **Start the MoA script:**
    ```bash
    python MoA.py
    ```

2.  **Follow the prompts:**
    * The script will first ask you to confirm the models and parameters (temperature, max tokens). You can press Enter to accept the defaults.
    * It will then prompt you to enter the scientific text you want to analyze.
    * The script will query the reference models, pass the results to the aggregate model, and print the final extracted data. The full console output will be saved to a file in the `moa_output/` directory.

#### Mode 2: In-depth Trajectory Analysis with MCTS

To generate and analyze the underlying reasoning paths of the extraction process, follow this two-step approach.

**Step 1: Generate Reasoning Trajectories (MCTS)**

Use the `MCTS_V7.py` script to generate diverse reasoning paths for a given text.

```bash
python MCTS_V7.py --query "Your scientific text for data extraction here..." --simulations 16 --depth 4
```
* `--query`: The raw scientific text from which to extract information.
* `--simulations`: The number of MCTS simulations to run.
* The results, including multiple candidate reasoning paths, will be saved to `material_extraction_trajectories.txt`.

**Step 2: Check Trajectory Consistency**

Use the `Consistency_V4.py` script to validate the consistency of the generated trajectories. This helps evaluate the reliability of different reasoning paths.

```bash
python Consistency_V4.py --file material_extraction_trajectories.txt
```
* `--file`: The path to the trajectory file generated by the MCTS script.
* A detailed consistency report will be saved to a new markdown file (e.g., `consistency_report_... .md`).


## Reproducibility Notice

Please note that the code in this repository represents the specific version used to generate the results for our paper. This work is part of a larger, ongoing research project, and this codebase will be actively maintained and may be updated in the future.

Furthermore, this project relies on third-party language models accessed via API. Our original experiments utilized models such as meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo. The availability of these models may change over time (e.g., models may be deprecated or removed by the API provider). If the original model is no longer available when you run the code, you may need to:

Modify the MODEL_NAME variable in the relevant script (e.g., MCTS_V7.py) to an available alternative.

Be aware that using a different model may lead to numerical results that do not perfectly match those reported in our paper, though the code can still be used to validate the proposed methodology.


## License

This project is licensed under the [MIT License](LICENSE).
